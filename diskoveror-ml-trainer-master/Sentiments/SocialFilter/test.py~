# -*- coding: utf-8 -*-

__author__ = "Inigo Solomon"


import pickle
import re, collections
import rake
import operator

### Insert Current Path
import os, sys, inspect, traceback
cmd_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile(inspect.currentframe()))[0]))
if cmd_folder not in sys.path:
    sys.path.insert(0, cmd_folder)

from Twokenize import twokenize


from nltk.corpus import stopwords

from nltk.stem import PorterStemmer
stemmer=PorterStemmer()
from SpellCheck.Corrector import spellCheck

path = cmd_folder+"/models/"
stoppath = "SmartStoplist.txt"
rake_object = rake.Rake(stoppath,4,2,1)
stop = stopwords.words('english')


class Filter(object):

    def __init__(self):


        self.wordDict = self.load_obj("wordDict")

        self.spellCheck = spellCheck()

        #Optional Stop Words Removal
        #Amazon nlp stop word list
        self.stop  = ['a', 'across', 'am', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'been', 'being', 'but', 'by', 'can', 'could', 'did', 'do', 'does', 'each', 'for', 'from', 'had', 'has', 'have', 'in', 'into', 'is', "isn't", 'it', "it'd", "it'll", "it's", 'its', 'of', 'on', 'or', 'that', "that's", 'thats', 'the', 'there', "there's", 'theres', 'these', 'this', 'those', 'to', 'under', 'until', 'up', 'were', 'will', 'with', 'would']
        self.stop+=[")","(",".","'",",",";",":","?","/","!","@","$","*","+","-","_","=","&","%","`","~","\"","{","}"]

    def load_obj(self,name ):
        with open( path + name + '.pkl', 'rb') as f:
            return pickle.load(f)

    def process(self,text,stopwordsF = 0, stemmerF = 0, encode = 1):

        # remove URL
        line = re.sub(twokenize.Url_RE," ", text)

        # to strip of extra white spaces
        temp = line.replace("#" , " ").lower().split()
        temp = " ".join(temp)
        #print temp

        tempTweet = ""

        for word in twokenize.tokenize(temp):
            """
                except:
                    tempTweet = " ".join([tempTweet,word.strip().decode("iso-8859-1")])
                    """



        #print(tempTweet.encode("utf-8"))
        if encode == 0:
            return(tempTweet)
        #return(tempTweet.encode("utf-8"))
        return temp

fil=Filter()
for line in open('twittersearchconnector.dat','r'):
    item=line.rstrip()
    #print item
    new=item.split('|')
    answ=new[4]
    #print answ
    #print "----TWEET-----"
    ans=fil.process(answ)
    #print ans
    print [i for i in ans.split() if i not in stop]
    #keywords = rake_object.run(ans)
    #print "Keywords:", keywords
